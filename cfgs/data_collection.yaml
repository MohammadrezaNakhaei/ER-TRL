defaults:
  - _self_
  - override hydra/hydra_logging: disabled  
  - override hydra/job_logging: disabled  

# this needs to be specified manually
experiment: test_exp

num_train_steps: 1000000

replay_buffer_capacity: ${num_train_steps}

num_seed_steps: 50000

eval_frequency: 50000

# deterministic evaluation by taking the mean of the distribution given by the actor
num_eval_episodes: 20

# stochastic evaluation by sampling from a distribution given by the actor
num_eval_sample_episodes: 50

# starting number for trajectories generated by run_evaluate() in pytorch_sac/train.py
eval_start_num: 0

device: cuda:0
#device: cpu


# logger
log_frequency: 50000
use_wandb: true

# video recorder
save_video: false
env_params:
  n_tasks: 40
  max_episode_steps: 200

seed: 0
goal_idx: 0
agent_name: 'sac'

agent_cfg:
  obs_dim: ??? # to be specified later
  action_dim: ??? # to be specified later
  action_range: [-1, 1] # to be specified later
  device: ${device}
  critic_cfg: 
    obs_dim: ${agent_cfg.obs_dim}
    action_dim: ${agent_cfg.action_dim}
    hidden_dim: 1024
    hidden_depth: 2  
  actor_cfg:
    obs_dim: ${agent_cfg.obs_dim}
    action_dim: ${agent_cfg.action_dim}
    hidden_depth: 2
    hidden_dim: 1024
    log_std_bounds: [-5, 2]
  discount: 0.99
  init_temperature: 0.1
  alpha_lr: 1e-4
  alpha_betas: [0.9, 0.999]
  actor_lr: 1e-4
  actor_betas: [0.9, 0.999]
  actor_update_frequency: 1
  critic_lr: 1e-4
  critic_betas: [0.9, 0.999]
  critic_tau: 0.005
  critic_target_update_frequency: 2
  batch_size: 1024

# hydra configuration    
hydra:  
  output_subdir: null  
  run:  
    dir: .
  
